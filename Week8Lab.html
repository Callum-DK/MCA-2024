<html>
<head>
  <title>My Portfolio Page 8</title>

</head>
<body>

  <h1>Week[8]</h1>
  
  <p>
    From the group lab session, we converted our chosen music peices to midi and played them through Musescore. 
    The music is played and represented as notes in a piano roll. The system takes into account pitch and rhythm
    as well as note length.
  </p>

  <p>
    It is noted that Musescore has its own midi instruments that are seamlessly looped and applied to the sheet 
    notation to playback.
  </p>

  <p>
    We exported our peice as a raw audio WAV file and imported this to sonic visualiser. An audio analysis app. 
    It was a stereo WAV file, primary data is located within the waveform. This waveform is drawn based on amplitude 
    and frequency. It shows the shape of a wave at a given time. This is a form of spectral representation.
  </p>

  <p>
    We created panes in sonic visualiser and generated a spectogram, all the percussive elements such as drums that
    have high amplitude could be seen visually as verticle peaks in the waveform. Pitch of a sound, was represented
    as parallel horizontal lines, where the lowest line corrosponds to the fundamental and the higher lines corrospond
    to the overtones. The spectogram shows the waveform as a heat map, with frequency on the vertical axis and time
    on the horizontal. Brightness of a colour on the heatmap determines the level of amplitude. Wave amplitude is 
    the distance between the peak or trough of a wave and its equilibrium position. Amplitude can be measured in decibles.
  </p>

<p>
  I discovered that it is possible to export the audio WAV file as a CSV file. Viewing this in an excel sheet, the table
  was filled with decible numbers. These act as specific time stamps within the peice. This could be used for fine audio editing.
  Can specifically be used for the likes of creating dubbed and synchronised versions of a video.
</p>

<p>
  Areas in space and time on spectrums within audio data will have a reference point listed as a numerical value within a CSV file.
</p>

  <p>
    Spectograms can help identify characterstics of signals that are non-stationary or nonlinear. We can deduce that audio data
    is represented differently from notation data. Audio data is represented in visual waveforms, graphs and heat maps. Notation
    is represented in print, with particualr rules. Notes in notation are seperated and put in sequencial order, they also factor
    in the type of instrument being used and the format can be change accordingly. A single note in raw audio data occupies multiple
    frequency bands. Audio data relates to original notation as we can see consistencies with notational rules and audio waveforms. 
    Note length, pitch and rhythm within sheet notation will respectfully corrospond to raw audio waveform analysis. Dynamics in sheet
    notation such as crescendo could relate to raw audio data and relate to the amplitude colour on a spectograph. Louder sounds
    will have a brighter colour due to more amplitude energy. 
  </p>

  <p>
    I identified 3 tracks in relation to my theme. My piece is a cinematic orchestral soundtrack
    for a film. I was able to download three cinematic style tracks that were different in sound and 
    style from the Free Music Archive. 
  </p>

  <p>
    <audio controls>
  <source src="Action Strings by Giacomo Forte.mp3" type="audio/mp3">
      </audio>
  </p>

  <p>
    <audio controls>
  <source src="Dreamworld by Denys Kyschchuk.mp3" type="audio/mp3">
      </audio>
    </p>

  <p>
     <audio controls>
  <source src="Hunt Him by Manuel Senfft.mp3" type="audio/mp3">
</audio>
  </p>

  <p>
    Sonic visualiser was used to gather some technical data from the tracks such as sample rate, bit depth, duration, 
    tempo and key. I thought these would be useful as regards my theme because Cinematic soundtracks being used for film
    will need to be high quality, and if they contain orchestral elements, chances are musicians will need notational information
    such as key and duration. 
  </p>

  <p>
  <img src="SonicRaw.png" alt="SonicRaw"
    style="max-width: 60%;"/>
    </p>

   <p>
  <img src="KeySonic.png" alt="KeySonic"
    style="max-width: 60%;"/>
    </p>


  <p>
To get the bits per second of each track I used the following bit rate calculation. Multiplying the bit depth by
  the sample rate. For example one track had 16 bits per sample and a sample rate of 44.1kHz. Converted kHz into Hz.
  </p>

  <p>
    The result was from 16x44,100 = 705,600 bps.
  </p>

  <p>
    The technical and non technical metadata was conducted into a table using google sheets. 
  </p>

  <p>
  <img src="Week8LabMetadata.png" alt="Week8LabMetadata"
    style="max-width: 70%;"/>
    </p>
  
</body> 
</html>
